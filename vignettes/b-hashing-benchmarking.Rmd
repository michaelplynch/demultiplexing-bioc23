---
title: "Simulated benchmarking of hashing based algorithms"
author: "Michael Lynch"
date: "`r Sys.Date()`"
bibliography: references.bib
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Hashing demultiplexing benchmarking}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
editor_options: 
  markdown: 
    wrap: 80
---

```{r eval=TRUE, include = FALSE}
knitr::opts_chunk$set(
    collapse = TRUE,
    comment = "#>",
    message = FALSE,
    fig.width = 7.5
)
```

```{r message=FALSE}
library(ComplexHeatmap)
library(viridisLite)
library(ggpubr)
library(dittoSeq)
library(utils)
library(SingleCellExperiment)
library(gridExtra)
library(Seurat)
library(cellhashR)
```



````{r}

source('../R/which_signal.R')
source('../R/draw_counts.R')
source('../R/plot_hashtag.R')
````

# Benchmarking cell hashing based methods

Testing algorithms on real data is a key step to evaluating true performance.
Real data includes nuances and factors which may not have been foreseen when developing the algorithm.
The cost of scRNASeq means that few demultiplexing benchmarking datasets are available and often results from other demultiplexing algorithms are used as ground truth.
As demultiplexing performance is closely tied to data quality and hetergenity, the few benchmarking datasets may not give a representative account of algorithm performance across the range of data quality observed in practice.

To overcome this, with the added benefit of hindsight, we simulate data to examine algorithm performance under specific conditions associated with poor hashing quality.

## Data generation

````{r}

mat<-logimat(ngroups=2,nsinglet=c(200,200),ndoub=50,nneg=50)
library(ComplexHeatmap)
mat[1:2,1:10]
Heatmap(mat)

counts<-draw_counts(size_sig=10,size_bg = 10,mu_sig = rep(50,2),mu_bg = rep(5,2),mat=mat,seed=1)
counts[1:2,c(1,201,401,451)]
Heatmap(log(counts++1))

myplots<-plot_hashtag(as.data.frame(t(counts)))
do.call(grid.arrange,myplots)
````

## cellhashR test

````{r}
#reticulate::py_config()
calls<-GenerateCellHashingCalls(barcodeMatrix=counts,methods="bff_cluster")
table(calls$bff_cluster)
````


## Overall demultiplexing performance reduces with signal/noise ratio

````{r}
mu1<-seq(80,20,-5)
acc<-c()
for (i in seq_along(mu1)) {

mat<-logimat(ngroups=4,nsinglet=rep(2000,4),ndoub=2000,nneg=200)
counts<-draw_counts(size_sig=10,size_bg = 10,mu_sig = rep(mu1[i],4),mu_bg = rep(5,4),mat=mat,seed=1)
hto<-SingleCellExperiment(list(counts=counts))

seurat<-CreateSeuratObject(counts=counts,assay="HTO")
seurat<-NormalizeData(seurat,normalization.method ="CLR")
seurat$hashtag<-colnames(counts)
seurat<-HTODemux(seurat)
acc[i]<-(sum(seurat$hashtag==seurat$hash.ID))/length(seurat$hashtag)

}
plot(mu1,acc)
myplots<-plot_hashtag(as.data.frame(t(counts)))
do.call(grid.arrange,myplots)
````

## FPR increases with small group size

````{r}
ncells<-seq(2000,100,-100)
acc<-c()
for (i in seq_along(ncells)) {

mat<-logimat(ngroups=4,nsinglet=c(2000,2000,2000,ncells[i]),ndoub=2000,nneg=200)
counts<-draw_counts(size_sig=10,size_bg = 10,mu_sig = rep(30,4),mu_bg = rep(5,4),mat=mat,seed=1)
hto<-SingleCellExperiment(list(counts=counts))

seurat<-CreateSeuratObject(counts=counts,assay="HTO")
seurat<-NormalizeData(seurat,normalization.method ="CLR")
seurat$hashtag<-colnames(counts)
seurat<-HTODemux(seurat)
acc[i]<-(sum(seurat$hashtag[seurat$hash.ID=="Hashtag4"]==seurat$hash.ID[seurat$hash.ID=="Hashtag4"]))/length(seurat$hashtag[seurat$hash.ID=="Hashtag4"])

}
plot(ncells,acc)
myplots<-plot_hashtag(as.data.frame(t(counts)))
do.call(grid.arrange,myplots)
````

## Reduction in signal/noise ratio in one group

````{r}
mu4<-seq(80,20,-10)
acc<-c()
for (i in seq_along(mu4)) {

mat<-logimat(ngroups=4,nsinglet=c(2000,2000,2000,2000),ndoub=2000,nneg=200)
counts<-draw_counts(size_sig=10,size_bg = 10,mu_sig = c(40,40,40,mu4[i]),mu_bg = rep(5,4),mat=mat,seed=1)
hto<-SingleCellExperiment(list(counts=counts))

seurat<-CreateSeuratObject(counts=counts,assay="HTO")
seurat<-NormalizeData(seurat,normalization.method ="CLR")
seurat$hashtag<-colnames(counts)
seurat<-HTODemux(seurat)
acc[i]<-(sum(seurat$hashtag[seurat$hashtag=="Hashtag4"]==seurat$hash.ID[seurat$hashtag=="Hashtag4"]))/length(seurat$hashtag[seurat$hashtag=="Hashtag4"])

}
plot(mu4,acc)
myplots<-plot_hashtag(as.data.frame(t(counts)))
do.call(grid.arrange,myplots)
````

## Reduction in signal/noise ratio and increased group size

````{r}
mu4<-seq(80,20,-10)
acc<-c()
for (i in seq_along(mu4)) {

mat<-logimat(ngroups=4,nsinglet=c(2000,2000,2000,4000),ndoub=2000,nneg=200)
counts<-draw_counts(size_sig=10,size_bg = 10,mu_sig = c(40,40,40,mu4[i]),mu_bg = rep(5,4),mat=mat,seed=1)
hto<-SingleCellExperiment(list(counts=counts))

seurat<-CreateSeuratObject(counts=counts,assay="HTO")
seurat<-NormalizeData(seurat,normalization.method ="CLR")
seurat$hashtag<-colnames(counts)
seurat<-HTODemux(seurat)
acc[i]<-(sum(seurat$hashtag[seurat$hashtag=="Hashtag4"]==seurat$hash.ID[seurat$hashtag=="Hashtag4"]))/length(seurat$hashtag[seurat$hashtag=="Hashtag4"])

}
plot(mu4,acc)
myplots<-plot_hashtag(as.data.frame(t(counts)))
do.call(grid.arrange,myplots)
````

# Session Info

```{r}
sessionInfo()
```

# References
